{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9xOSj7V-fbp",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "pip install kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqzjR9FX-32w",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "5cd7234e-81fc-44c6-ec39-d337c294494b"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9f7cb7e2-6462-4386-b4f3-a318b773236d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-9f7cb7e2-6462-4386-b4f3-a318b773236d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle (1).json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"ahmedali2019\",\"key\":\"f87c00b4560debffb065fc3c68ec5118\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyXV_XC3-36J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#before importing the dataset we want to use this code\n",
        "# The Kaggle API client expects this file to be in ~/.kaggle,\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "\n",
        "# This permissions change avoids a warning on Kaggle tool startup.\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIEdfbty-4Ci",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c8802785-42b8-4bdf-8ccd-c962348af12b"
      },
      "source": [
        "!kaggle datasets download -d deadskull7/fer2013\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fer2013.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04GFXX1i-4Fh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import zipfile\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJ59nGa2-4N1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1b340e44-d33a-44ed-a23e-1e78cf0c5da8"
      },
      "source": [
        "zf = zipfile.ZipFile('fer2013.zip')\n",
        "uncompress_size = sum((file.file_size for file in zf.infolist()))\n",
        "extracted_size = 0\n",
        "for file in tqdm(zf.infolist()):\n",
        "    extracted_size += file.file_size\n",
        "    zf.extract(file)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:02<00:00,  2.23s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VFdxxXj-4RN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhkhva2t-4Zg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import Activation, Convolution2D, Dropout, Conv2D\n",
        "from keras.layers import AveragePooling2D, BatchNormalization\n",
        "from keras.layers import GlobalAveragePooling2D\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import SeparableConv2D\n",
        "from keras import layers\n",
        "from keras.regularizers import l2\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import numpy as np"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdhqIhVN-4dG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_path = '/content/fer2013.csv'\n",
        "image_size=(48,48)\n",
        "# parameters\n",
        "batch_size = 32\n",
        "num_epochs = 200\n",
        "input_shape = (48, 48, 1)\n",
        "validation_split = .2\n",
        "verbose = 1\n",
        "num_classes = 7\n",
        "patience = 50\n",
        "base_path = 'models/'\n",
        "l2_regularization=0.01\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E253zk4C-4jR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def load_fer2013():\n",
        "\tdata = pd.read_csv(dataset_path)\n",
        "\tpixels = data['pixels'].tolist()\n",
        "\twidth, height = 48, 48\n",
        "\tfaces = []\n",
        "\tfor pixel_sequence in tqdm(pixels):\n",
        "\t\tface = [int(pixel) for pixel in pixel_sequence.split(' ')]\n",
        "\t\tface = np.asarray(face).reshape(width, height)\n",
        "\t\tface = cv2.resize(face.astype('uint8'),image_size)\n",
        "\t\tfaces.append(face.astype('float32'))\n",
        "\tfaces = np.asarray(faces)\n",
        "\tfaces = np.expand_dims(faces, -1)\n",
        "\temotions = pd.get_dummies(data['emotion']).to_numpy()\n",
        " #.as_matrix()\n",
        "\treturn faces, emotions\n",
        "\n",
        "#df['Price']\n",
        "\n",
        "\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-8I6KCTByhq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_input(x, v2=True):\n",
        "    x = x.astype('float32')\n",
        "    x = x / 255.0\n",
        "    if v2:\n",
        "        x = x - 0.5\n",
        "        x = x * 2.0\n",
        "    return x"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_vtUG5Q-4o8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# data generator\n",
        "data_generator = ImageDataGenerator(\n",
        "                        featurewise_center=False,\n",
        "                        featurewise_std_normalization=False,\n",
        "                        rotation_range=10,\n",
        "                        width_shift_range=0.1,\n",
        "                        height_shift_range=0.1,\n",
        "                        zoom_range=.1,\n",
        "                        horizontal_flip=True)\n"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42Y_P90I-4se",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "30e6e1ca-b09d-46cc-ccbe-5b9a52cf4597"
      },
      "source": [
        "regularization = l2(l2_regularization)\n",
        "\n",
        "# base\n",
        "img_input = Input(input_shape)\n",
        "x = Conv2D(8, (3, 3), strides=(1, 1), kernel_regularizer=regularization, use_bias=False)(img_input)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Conv2D(8, (3, 3), strides=(1, 1), kernel_regularizer=regularization, use_bias=False)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "\n",
        "# module 1\n",
        "residual = Conv2D(16, (1, 1), strides=(2, 2), padding='same', use_bias=False)(x)\n",
        "residual = BatchNormalization()(residual)\n",
        "x = SeparableConv2D(16, (3, 3), padding='same', kernel_regularizer=regularization, use_bias=False)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = SeparableConv2D(16, (3, 3), padding='same', kernel_regularizer=regularization, use_bias=False)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
        "x = layers.add([x, residual])\n",
        "\n",
        "# module 2\n",
        "residual = Conv2D(32, (1, 1), strides=(2, 2), padding='same', use_bias=False)(x)\n",
        "residual = BatchNormalization()(residual)\n",
        "x = SeparableConv2D(32, (3, 3), padding='same', kernel_regularizer=regularization, use_bias=False)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = SeparableConv2D(32, (3, 3), padding='same', kernel_regularizer=regularization, use_bias=False)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
        "x = layers.add([x, residual])\n",
        "\n",
        "# module 3\n",
        "residual = Conv2D(64, (1, 1), strides=(2, 2),padding='same', use_bias=False)(x)\n",
        "residual = BatchNormalization()(residual)\n",
        "x = SeparableConv2D(64, (3, 3), padding='same',kernel_regularizer=regularization,use_bias=False)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = SeparableConv2D(64, (3, 3), padding='same',kernel_regularizer=regularization,use_bias=False)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
        "x = layers.add([x, residual])\n",
        "\n",
        "# module 4\n",
        "residual = Conv2D(128, (1, 1), strides=(2, 2),padding='same', use_bias=False)(x)\n",
        "residual = BatchNormalization()(residual)\n",
        "x = SeparableConv2D(128, (3, 3), padding='same',kernel_regularizer=regularization,use_bias=False)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = SeparableConv2D(128, (3, 3), padding='same',kernel_regularizer=regularization,use_bias=False)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
        "x = layers.add([x, residual])\n",
        "x = Conv2D(num_classes, (3, 3), padding='same')(x)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "output = Activation('softmax',name='predictions')(x)\n",
        "\n",
        "model = Model(img_input, output)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "model.summary()\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 48, 48, 1)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 46, 46, 8)    72          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 46, 46, 8)    32          conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 46, 46, 8)    0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 44, 44, 8)    576         activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 44, 44, 8)    32          conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 44, 44, 8)    0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_9 (SeparableCo (None, 44, 44, 16)   200         activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 44, 44, 16)   64          separable_conv2d_9[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 44, 44, 16)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_10 (SeparableC (None, 44, 44, 16)   400         activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 44, 44, 16)   64          separable_conv2d_10[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 22, 22, 16)   128         activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 22, 22, 16)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 22, 22, 16)   64          conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 22, 22, 16)   0           max_pooling2d_5[0][0]            \n",
            "                                                                 batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_11 (SeparableC (None, 22, 22, 32)   656         add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 22, 22, 32)   128         separable_conv2d_11[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 22, 22, 32)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_12 (SeparableC (None, 22, 22, 32)   1312        activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 22, 22, 32)   128         separable_conv2d_12[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 11, 11, 32)   512         add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 11, 11, 32)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 11, 11, 32)   128         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 11, 11, 32)   0           max_pooling2d_6[0][0]            \n",
            "                                                                 batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_13 (SeparableC (None, 11, 11, 64)   2336        add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 11, 11, 64)   256         separable_conv2d_13[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 11, 11, 64)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_14 (SeparableC (None, 11, 11, 64)   4672        activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 11, 11, 64)   256         separable_conv2d_14[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 6, 6, 64)     2048        add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2D)  (None, 6, 6, 64)     0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 6, 6, 64)     256         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 6, 6, 64)     0           max_pooling2d_7[0][0]            \n",
            "                                                                 batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_15 (SeparableC (None, 6, 6, 128)    8768        add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 6, 6, 128)    512         separable_conv2d_15[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 6, 6, 128)    0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_16 (SeparableC (None, 6, 6, 128)    17536       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 6, 6, 128)    512         separable_conv2d_16[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 3, 3, 128)    8192        add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2D)  (None, 3, 3, 128)    0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 3, 3, 128)    512         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 3, 3, 128)    0           max_pooling2d_8[0][0]            \n",
            "                                                                 batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 3, 3, 7)      8071        add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_2 (Glo (None, 7)            0           conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "predictions (Activation)        (None, 7)            0           global_average_pooling2d_2[0][0] \n",
            "==================================================================================================\n",
            "Total params: 58,423\n",
            "Trainable params: 56,951\n",
            "Non-trainable params: 1,472\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qC9jF3fi-44g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "79c12885-03b4-4621-caa7-529b85520876"
      },
      "source": [
        "\n",
        "# loading dataset\n",
        "faces, emotions = load_fer2013()\n",
        "\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 35887/35887 [00:21<00:00, 1664.64it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oISMl3QOFG7m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "faces = preprocess_input(faces)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnIhy9j0FUUL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_samples, num_classes = emotions.shape"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uce0qMUFVlK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xtrain, xtest,ytrain,ytest = train_test_split(faces, emotions,test_size=0.2,shuffle=True)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvO_9FLs-5CN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9ad48e00-0aac-4729-b513-cb8c85ba1afe"
      },
      "source": [
        "history =model.fit_generator(data_generator.flow(xtrain, ytrain,\n",
        "                                            batch_size),\n",
        "                        steps_per_epoch=len(xtrain) / batch_size,\n",
        "                        epochs=num_epochs, verbose=1,\n",
        "                        validation_data=(xtest,ytest))\n",
        "model.save(\"my_Model.h5\")\n",
        "model.save(\"my_Model.hdf5\")\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "898/897 [==============================] - 44s 49ms/step - loss: 1.7589 - accuracy: 0.3346 - val_loss: 1.7295 - val_accuracy: 0.3863\n",
            "Epoch 2/200\n",
            "898/897 [==============================] - 35s 38ms/step - loss: 1.5070 - accuracy: 0.4327 - val_loss: 1.6036 - val_accuracy: 0.4138\n",
            "Epoch 3/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 1.3829 - accuracy: 0.4813 - val_loss: 1.4381 - val_accuracy: 0.4645\n",
            "Epoch 4/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 1.3181 - accuracy: 0.5025 - val_loss: 1.3210 - val_accuracy: 0.4950\n",
            "Epoch 5/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 1.2776 - accuracy: 0.5206 - val_loss: 1.2240 - val_accuracy: 0.5476\n",
            "Epoch 6/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 1.2413 - accuracy: 0.5349 - val_loss: 1.2631 - val_accuracy: 0.5371\n",
            "Epoch 7/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 1.2126 - accuracy: 0.5465 - val_loss: 1.2311 - val_accuracy: 0.5481\n",
            "Epoch 8/200\n",
            "898/897 [==============================] - 35s 38ms/step - loss: 1.1925 - accuracy: 0.5518 - val_loss: 1.2039 - val_accuracy: 0.5482\n",
            "Epoch 9/200\n",
            "898/897 [==============================] - 34s 38ms/step - loss: 1.1696 - accuracy: 0.5628 - val_loss: 1.1323 - val_accuracy: 0.5818\n",
            "Epoch 10/200\n",
            "898/897 [==============================] - 35s 38ms/step - loss: 1.1571 - accuracy: 0.5700 - val_loss: 1.1875 - val_accuracy: 0.5638\n",
            "Epoch 11/200\n",
            "898/897 [==============================] - 34s 38ms/step - loss: 1.1364 - accuracy: 0.5778 - val_loss: 1.2149 - val_accuracy: 0.5666\n",
            "Epoch 12/200\n",
            "898/897 [==============================] - 34s 38ms/step - loss: 1.1268 - accuracy: 0.5776 - val_loss: 1.2535 - val_accuracy: 0.5354\n",
            "Epoch 13/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 1.1153 - accuracy: 0.5846 - val_loss: 1.1935 - val_accuracy: 0.5628\n",
            "Epoch 14/200\n",
            "898/897 [==============================] - 34s 38ms/step - loss: 1.1040 - accuracy: 0.5878 - val_loss: 1.1164 - val_accuracy: 0.5790\n",
            "Epoch 15/200\n",
            "898/897 [==============================] - 34s 38ms/step - loss: 1.0947 - accuracy: 0.5911 - val_loss: 1.2368 - val_accuracy: 0.5617\n",
            "Epoch 16/200\n",
            "898/897 [==============================] - 34s 38ms/step - loss: 1.0879 - accuracy: 0.5930 - val_loss: 1.0983 - val_accuracy: 0.5910\n",
            "Epoch 17/200\n",
            "898/897 [==============================] - 34s 38ms/step - loss: 1.0774 - accuracy: 0.5946 - val_loss: 1.1598 - val_accuracy: 0.5644\n",
            "Epoch 18/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 1.0690 - accuracy: 0.6054 - val_loss: 1.1085 - val_accuracy: 0.5908\n",
            "Epoch 19/200\n",
            "898/897 [==============================] - 34s 38ms/step - loss: 1.0696 - accuracy: 0.6018 - val_loss: 1.1159 - val_accuracy: 0.5860\n",
            "Epoch 20/200\n",
            "898/897 [==============================] - 34s 38ms/step - loss: 1.0553 - accuracy: 0.6077 - val_loss: 1.1189 - val_accuracy: 0.5819\n",
            "Epoch 21/200\n",
            "898/897 [==============================] - 34s 38ms/step - loss: 1.0511 - accuracy: 0.6073 - val_loss: 1.1315 - val_accuracy: 0.5826\n",
            "Epoch 22/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 1.0482 - accuracy: 0.6098 - val_loss: 1.1859 - val_accuracy: 0.5701\n",
            "Epoch 23/200\n",
            "898/897 [==============================] - 34s 38ms/step - loss: 1.0378 - accuracy: 0.6177 - val_loss: 1.1041 - val_accuracy: 0.5821\n",
            "Epoch 24/200\n",
            "898/897 [==============================] - 34s 38ms/step - loss: 1.0340 - accuracy: 0.6160 - val_loss: 1.1357 - val_accuracy: 0.5861\n",
            "Epoch 25/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 1.0278 - accuracy: 0.6191 - val_loss: 1.0949 - val_accuracy: 0.5946\n",
            "Epoch 26/200\n",
            "898/897 [==============================] - 34s 38ms/step - loss: 1.0242 - accuracy: 0.6198 - val_loss: 1.1083 - val_accuracy: 0.5858\n",
            "Epoch 27/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 1.0262 - accuracy: 0.6199 - val_loss: 1.1307 - val_accuracy: 0.5790\n",
            "Epoch 28/200\n",
            "898/897 [==============================] - 34s 38ms/step - loss: 1.0121 - accuracy: 0.6195 - val_loss: 1.0519 - val_accuracy: 0.6151\n",
            "Epoch 29/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 1.0122 - accuracy: 0.6235 - val_loss: 1.0907 - val_accuracy: 0.5954\n",
            "Epoch 30/200\n",
            "898/897 [==============================] - 34s 38ms/step - loss: 1.0041 - accuracy: 0.6258 - val_loss: 1.0915 - val_accuracy: 0.5995\n",
            "Epoch 31/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 1.0027 - accuracy: 0.6237 - val_loss: 1.0853 - val_accuracy: 0.5914\n",
            "Epoch 32/200\n",
            "898/897 [==============================] - 34s 38ms/step - loss: 0.9946 - accuracy: 0.6283 - val_loss: 1.0568 - val_accuracy: 0.6092\n",
            "Epoch 33/200\n",
            "898/897 [==============================] - 34s 38ms/step - loss: 0.9941 - accuracy: 0.6294 - val_loss: 1.1216 - val_accuracy: 0.5958\n",
            "Epoch 34/200\n",
            "898/897 [==============================] - 34s 38ms/step - loss: 0.9951 - accuracy: 0.6298 - val_loss: 1.0955 - val_accuracy: 0.6013\n",
            "Epoch 35/200\n",
            "898/897 [==============================] - 34s 38ms/step - loss: 0.9885 - accuracy: 0.6317 - val_loss: 1.0588 - val_accuracy: 0.6099\n",
            "Epoch 36/200\n",
            "898/897 [==============================] - 35s 38ms/step - loss: 0.9827 - accuracy: 0.6327 - val_loss: 1.0629 - val_accuracy: 0.6060\n",
            "Epoch 37/200\n",
            "898/897 [==============================] - 34s 38ms/step - loss: 0.9798 - accuracy: 0.6376 - val_loss: 1.0944 - val_accuracy: 0.6045\n",
            "Epoch 38/200\n",
            "898/897 [==============================] - 34s 38ms/step - loss: 0.9791 - accuracy: 0.6351 - val_loss: 1.0920 - val_accuracy: 0.6020\n",
            "Epoch 39/200\n",
            "898/897 [==============================] - 35s 38ms/step - loss: 0.9773 - accuracy: 0.6367 - val_loss: 1.0897 - val_accuracy: 0.5956\n",
            "Epoch 40/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.9761 - accuracy: 0.6396 - val_loss: 1.0660 - val_accuracy: 0.6123\n",
            "Epoch 41/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.9723 - accuracy: 0.6394 - val_loss: 1.0777 - val_accuracy: 0.6018\n",
            "Epoch 42/200\n",
            "898/897 [==============================] - 34s 38ms/step - loss: 0.9679 - accuracy: 0.6408 - val_loss: 1.0803 - val_accuracy: 0.6031\n",
            "Epoch 43/200\n",
            "898/897 [==============================] - 35s 38ms/step - loss: 0.9616 - accuracy: 0.6419 - val_loss: 1.0366 - val_accuracy: 0.6183\n",
            "Epoch 44/200\n",
            "898/897 [==============================] - 34s 38ms/step - loss: 0.9625 - accuracy: 0.6423 - val_loss: 1.0654 - val_accuracy: 0.6045\n",
            "Epoch 45/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.9644 - accuracy: 0.6406 - val_loss: 1.1123 - val_accuracy: 0.5910\n",
            "Epoch 46/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.9603 - accuracy: 0.6412 - val_loss: 1.0535 - val_accuracy: 0.6167\n",
            "Epoch 47/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.9545 - accuracy: 0.6443 - val_loss: 1.0327 - val_accuracy: 0.6195\n",
            "Epoch 48/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.9452 - accuracy: 0.6461 - val_loss: 1.0467 - val_accuracy: 0.6087\n",
            "Epoch 49/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.9507 - accuracy: 0.6454 - val_loss: 1.0449 - val_accuracy: 0.6174\n",
            "Epoch 50/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.9431 - accuracy: 0.6478 - val_loss: 1.0706 - val_accuracy: 0.6127\n",
            "Epoch 51/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.9446 - accuracy: 0.6481 - val_loss: 1.0852 - val_accuracy: 0.6004\n",
            "Epoch 52/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.9403 - accuracy: 0.6471 - val_loss: 1.1097 - val_accuracy: 0.5940\n",
            "Epoch 53/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.9387 - accuracy: 0.6491 - val_loss: 1.0245 - val_accuracy: 0.6216\n",
            "Epoch 54/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.9377 - accuracy: 0.6517 - val_loss: 1.1100 - val_accuracy: 0.5949\n",
            "Epoch 55/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.9328 - accuracy: 0.6549 - val_loss: 1.0646 - val_accuracy: 0.6035\n",
            "Epoch 56/200\n",
            "898/897 [==============================] - 34s 38ms/step - loss: 0.9370 - accuracy: 0.6524 - val_loss: 1.0855 - val_accuracy: 0.6020\n",
            "Epoch 57/200\n",
            "898/897 [==============================] - 34s 38ms/step - loss: 0.9367 - accuracy: 0.6513 - val_loss: 1.0523 - val_accuracy: 0.6215\n",
            "Epoch 58/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.9309 - accuracy: 0.6514 - val_loss: 1.0754 - val_accuracy: 0.6082\n",
            "Epoch 59/200\n",
            "898/897 [==============================] - 34s 38ms/step - loss: 0.9307 - accuracy: 0.6526 - val_loss: 1.0474 - val_accuracy: 0.6116\n",
            "Epoch 60/200\n",
            "898/897 [==============================] - 34s 38ms/step - loss: 0.9276 - accuracy: 0.6536 - val_loss: 1.0248 - val_accuracy: 0.6213\n",
            "Epoch 61/200\n",
            "898/897 [==============================] - 34s 38ms/step - loss: 0.9201 - accuracy: 0.6588 - val_loss: 1.0307 - val_accuracy: 0.6266\n",
            "Epoch 62/200\n",
            "898/897 [==============================] - 35s 38ms/step - loss: 0.9220 - accuracy: 0.6570 - val_loss: 1.0504 - val_accuracy: 0.6117\n",
            "Epoch 63/200\n",
            "898/897 [==============================] - 34s 38ms/step - loss: 0.9220 - accuracy: 0.6571 - val_loss: 1.0733 - val_accuracy: 0.6013\n",
            "Epoch 64/200\n",
            "898/897 [==============================] - 34s 38ms/step - loss: 0.9213 - accuracy: 0.6575 - val_loss: 1.0494 - val_accuracy: 0.6148\n",
            "Epoch 65/200\n",
            "898/897 [==============================] - 34s 38ms/step - loss: 0.9162 - accuracy: 0.6586 - val_loss: 1.0784 - val_accuracy: 0.6119\n",
            "Epoch 66/200\n",
            "898/897 [==============================] - 34s 38ms/step - loss: 0.9128 - accuracy: 0.6589 - val_loss: 1.0885 - val_accuracy: 0.6039\n",
            "Epoch 67/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.9137 - accuracy: 0.6622 - val_loss: 1.0439 - val_accuracy: 0.6201\n",
            "Epoch 68/200\n",
            "898/897 [==============================] - 34s 38ms/step - loss: 0.9103 - accuracy: 0.6618 - val_loss: 1.0894 - val_accuracy: 0.6020\n",
            "Epoch 69/200\n",
            "898/897 [==============================] - 35s 38ms/step - loss: 0.9126 - accuracy: 0.6590 - val_loss: 1.0643 - val_accuracy: 0.6056\n",
            "Epoch 70/200\n",
            "898/897 [==============================] - 34s 38ms/step - loss: 0.9067 - accuracy: 0.6652 - val_loss: 1.0622 - val_accuracy: 0.6113\n",
            "Epoch 71/200\n",
            "898/897 [==============================] - 35s 38ms/step - loss: 0.9051 - accuracy: 0.6665 - val_loss: 1.0297 - val_accuracy: 0.6215\n",
            "Epoch 72/200\n",
            "898/897 [==============================] - 34s 38ms/step - loss: 0.9088 - accuracy: 0.6602 - val_loss: 1.0722 - val_accuracy: 0.6140\n",
            "Epoch 73/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.9013 - accuracy: 0.6647 - val_loss: 1.0910 - val_accuracy: 0.6053\n",
            "Epoch 74/200\n",
            "898/897 [==============================] - 35s 38ms/step - loss: 0.9005 - accuracy: 0.6664 - val_loss: 1.0651 - val_accuracy: 0.6241\n",
            "Epoch 75/200\n",
            "898/897 [==============================] - 34s 38ms/step - loss: 0.9038 - accuracy: 0.6640 - val_loss: 1.0505 - val_accuracy: 0.6123\n",
            "Epoch 76/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8966 - accuracy: 0.6646 - val_loss: 1.0781 - val_accuracy: 0.6130\n",
            "Epoch 77/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8976 - accuracy: 0.6703 - val_loss: 1.0413 - val_accuracy: 0.6245\n",
            "Epoch 78/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8932 - accuracy: 0.6719 - val_loss: 1.0853 - val_accuracy: 0.6134\n",
            "Epoch 79/200\n",
            "898/897 [==============================] - 34s 38ms/step - loss: 0.8994 - accuracy: 0.6677 - val_loss: 1.1005 - val_accuracy: 0.6102\n",
            "Epoch 80/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8952 - accuracy: 0.6684 - val_loss: 1.0453 - val_accuracy: 0.6191\n",
            "Epoch 81/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8927 - accuracy: 0.6715 - val_loss: 1.0515 - val_accuracy: 0.6206\n",
            "Epoch 82/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8914 - accuracy: 0.6712 - val_loss: 1.0578 - val_accuracy: 0.6120\n",
            "Epoch 83/200\n",
            "898/897 [==============================] - 35s 38ms/step - loss: 0.8916 - accuracy: 0.6701 - val_loss: 1.1053 - val_accuracy: 0.6127\n",
            "Epoch 84/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8909 - accuracy: 0.6694 - val_loss: 1.0459 - val_accuracy: 0.6266\n",
            "Epoch 85/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8842 - accuracy: 0.6688 - val_loss: 1.0794 - val_accuracy: 0.6126\n",
            "Epoch 86/200\n",
            "898/897 [==============================] - 34s 38ms/step - loss: 0.8798 - accuracy: 0.6737 - val_loss: 1.0506 - val_accuracy: 0.6222\n",
            "Epoch 87/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8864 - accuracy: 0.6710 - val_loss: 1.0484 - val_accuracy: 0.6138\n",
            "Epoch 88/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8849 - accuracy: 0.6724 - val_loss: 1.0723 - val_accuracy: 0.6173\n",
            "Epoch 89/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8826 - accuracy: 0.6762 - val_loss: 1.0256 - val_accuracy: 0.6298\n",
            "Epoch 90/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8769 - accuracy: 0.6736 - val_loss: 1.0516 - val_accuracy: 0.6272\n",
            "Epoch 91/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8753 - accuracy: 0.6757 - val_loss: 1.0556 - val_accuracy: 0.6251\n",
            "Epoch 92/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8812 - accuracy: 0.6752 - val_loss: 1.0971 - val_accuracy: 0.6091\n",
            "Epoch 93/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8789 - accuracy: 0.6749 - val_loss: 1.0545 - val_accuracy: 0.6290\n",
            "Epoch 94/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8688 - accuracy: 0.6778 - val_loss: 1.0597 - val_accuracy: 0.6181\n",
            "Epoch 95/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8699 - accuracy: 0.6782 - val_loss: 1.0355 - val_accuracy: 0.6225\n",
            "Epoch 96/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8752 - accuracy: 0.6769 - val_loss: 1.0625 - val_accuracy: 0.6186\n",
            "Epoch 97/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8741 - accuracy: 0.6767 - val_loss: 1.0572 - val_accuracy: 0.6180\n",
            "Epoch 98/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8661 - accuracy: 0.6784 - val_loss: 1.0860 - val_accuracy: 0.6232\n",
            "Epoch 99/200\n",
            "898/897 [==============================] - 34s 38ms/step - loss: 0.8684 - accuracy: 0.6770 - val_loss: 1.0452 - val_accuracy: 0.6251\n",
            "Epoch 100/200\n",
            "898/897 [==============================] - 34s 38ms/step - loss: 0.8711 - accuracy: 0.6781 - val_loss: 1.0695 - val_accuracy: 0.6212\n",
            "Epoch 101/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8666 - accuracy: 0.6787 - val_loss: 1.0375 - val_accuracy: 0.6304\n",
            "Epoch 102/200\n",
            "898/897 [==============================] - 34s 38ms/step - loss: 0.8627 - accuracy: 0.6775 - val_loss: 1.0549 - val_accuracy: 0.6208\n",
            "Epoch 103/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8653 - accuracy: 0.6799 - val_loss: 1.0349 - val_accuracy: 0.6314\n",
            "Epoch 104/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8610 - accuracy: 0.6772 - val_loss: 1.0379 - val_accuracy: 0.6298\n",
            "Epoch 105/200\n",
            "898/897 [==============================] - 34s 38ms/step - loss: 0.8613 - accuracy: 0.6802 - val_loss: 1.0665 - val_accuracy: 0.6226\n",
            "Epoch 106/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8636 - accuracy: 0.6810 - val_loss: 1.0726 - val_accuracy: 0.6120\n",
            "Epoch 107/200\n",
            "898/897 [==============================] - 35s 38ms/step - loss: 0.8604 - accuracy: 0.6803 - val_loss: 1.0940 - val_accuracy: 0.6084\n",
            "Epoch 108/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8644 - accuracy: 0.6799 - val_loss: 1.0425 - val_accuracy: 0.6297\n",
            "Epoch 109/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8555 - accuracy: 0.6851 - val_loss: 1.0755 - val_accuracy: 0.6137\n",
            "Epoch 110/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8576 - accuracy: 0.6807 - val_loss: 1.0543 - val_accuracy: 0.6244\n",
            "Epoch 111/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8569 - accuracy: 0.6830 - val_loss: 1.0534 - val_accuracy: 0.6250\n",
            "Epoch 112/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8553 - accuracy: 0.6826 - val_loss: 1.0596 - val_accuracy: 0.6176\n",
            "Epoch 113/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8539 - accuracy: 0.6832 - val_loss: 1.0794 - val_accuracy: 0.6142\n",
            "Epoch 114/200\n",
            "898/897 [==============================] - 35s 38ms/step - loss: 0.8587 - accuracy: 0.6839 - val_loss: 1.0808 - val_accuracy: 0.6138\n",
            "Epoch 115/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8469 - accuracy: 0.6852 - val_loss: 1.0936 - val_accuracy: 0.6103\n",
            "Epoch 116/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8521 - accuracy: 0.6866 - val_loss: 1.0428 - val_accuracy: 0.6258\n",
            "Epoch 117/200\n",
            "898/897 [==============================] - 35s 38ms/step - loss: 0.8478 - accuracy: 0.6866 - val_loss: 1.1117 - val_accuracy: 0.6113\n",
            "Epoch 118/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8456 - accuracy: 0.6871 - val_loss: 1.0616 - val_accuracy: 0.6218\n",
            "Epoch 119/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8516 - accuracy: 0.6856 - val_loss: 1.1315 - val_accuracy: 0.6076\n",
            "Epoch 120/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8495 - accuracy: 0.6866 - val_loss: 1.0317 - val_accuracy: 0.6258\n",
            "Epoch 121/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8386 - accuracy: 0.6899 - val_loss: 1.0171 - val_accuracy: 0.6282\n",
            "Epoch 122/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8472 - accuracy: 0.6852 - val_loss: 1.0639 - val_accuracy: 0.6163\n",
            "Epoch 123/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8421 - accuracy: 0.6865 - val_loss: 1.0412 - val_accuracy: 0.6258\n",
            "Epoch 124/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8484 - accuracy: 0.6849 - val_loss: 1.0629 - val_accuracy: 0.6204\n",
            "Epoch 125/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8512 - accuracy: 0.6824 - val_loss: 1.0781 - val_accuracy: 0.6179\n",
            "Epoch 126/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8435 - accuracy: 0.6914 - val_loss: 1.1659 - val_accuracy: 0.5991\n",
            "Epoch 127/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8414 - accuracy: 0.6881 - val_loss: 1.0708 - val_accuracy: 0.6158\n",
            "Epoch 128/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8344 - accuracy: 0.6920 - val_loss: 1.0659 - val_accuracy: 0.6202\n",
            "Epoch 129/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8408 - accuracy: 0.6903 - val_loss: 1.1013 - val_accuracy: 0.6069\n",
            "Epoch 130/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8420 - accuracy: 0.6897 - val_loss: 1.1010 - val_accuracy: 0.6155\n",
            "Epoch 131/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8405 - accuracy: 0.6895 - val_loss: 1.1122 - val_accuracy: 0.6021\n",
            "Epoch 132/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8383 - accuracy: 0.6888 - val_loss: 1.0631 - val_accuracy: 0.6160\n",
            "Epoch 133/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8397 - accuracy: 0.6871 - val_loss: 1.0686 - val_accuracy: 0.6156\n",
            "Epoch 134/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8342 - accuracy: 0.6920 - val_loss: 1.0632 - val_accuracy: 0.6211\n",
            "Epoch 135/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8355 - accuracy: 0.6950 - val_loss: 1.0715 - val_accuracy: 0.6201\n",
            "Epoch 136/200\n",
            "898/897 [==============================] - 36s 40ms/step - loss: 0.8360 - accuracy: 0.6895 - val_loss: 1.0341 - val_accuracy: 0.6321\n",
            "Epoch 137/200\n",
            "898/897 [==============================] - 36s 40ms/step - loss: 0.8329 - accuracy: 0.6911 - val_loss: 1.0589 - val_accuracy: 0.6349\n",
            "Epoch 138/200\n",
            "898/897 [==============================] - 36s 40ms/step - loss: 0.8372 - accuracy: 0.6910 - val_loss: 1.0610 - val_accuracy: 0.6273\n",
            "Epoch 139/200\n",
            "898/897 [==============================] - 36s 40ms/step - loss: 0.8337 - accuracy: 0.6900 - val_loss: 1.0554 - val_accuracy: 0.6308\n",
            "Epoch 140/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8337 - accuracy: 0.6925 - val_loss: 1.0722 - val_accuracy: 0.6181\n",
            "Epoch 141/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8317 - accuracy: 0.6911 - val_loss: 1.0803 - val_accuracy: 0.6222\n",
            "Epoch 142/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8290 - accuracy: 0.6945 - val_loss: 1.0633 - val_accuracy: 0.6284\n",
            "Epoch 143/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8264 - accuracy: 0.6918 - val_loss: 1.0985 - val_accuracy: 0.6162\n",
            "Epoch 144/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8290 - accuracy: 0.6919 - val_loss: 1.0573 - val_accuracy: 0.6303\n",
            "Epoch 145/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8302 - accuracy: 0.6927 - val_loss: 1.0434 - val_accuracy: 0.6293\n",
            "Epoch 146/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8279 - accuracy: 0.6957 - val_loss: 1.0602 - val_accuracy: 0.6312\n",
            "Epoch 147/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8186 - accuracy: 0.6965 - val_loss: 1.0805 - val_accuracy: 0.6257\n",
            "Epoch 148/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8316 - accuracy: 0.6930 - val_loss: 1.0796 - val_accuracy: 0.6209\n",
            "Epoch 149/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8227 - accuracy: 0.6961 - val_loss: 1.0889 - val_accuracy: 0.6165\n",
            "Epoch 150/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8261 - accuracy: 0.6927 - val_loss: 1.0481 - val_accuracy: 0.6332\n",
            "Epoch 151/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8213 - accuracy: 0.6935 - val_loss: 1.1131 - val_accuracy: 0.6089\n",
            "Epoch 152/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8192 - accuracy: 0.6970 - val_loss: 1.1060 - val_accuracy: 0.6070\n",
            "Epoch 153/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8259 - accuracy: 0.6964 - val_loss: 1.0737 - val_accuracy: 0.6232\n",
            "Epoch 154/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8270 - accuracy: 0.6948 - val_loss: 1.0700 - val_accuracy: 0.6237\n",
            "Epoch 155/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8205 - accuracy: 0.6957 - val_loss: 1.0640 - val_accuracy: 0.6236\n",
            "Epoch 156/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8193 - accuracy: 0.6943 - val_loss: 1.0895 - val_accuracy: 0.6147\n",
            "Epoch 157/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8186 - accuracy: 0.6987 - val_loss: 1.0688 - val_accuracy: 0.6226\n",
            "Epoch 158/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8222 - accuracy: 0.6956 - val_loss: 1.0718 - val_accuracy: 0.6286\n",
            "Epoch 159/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8148 - accuracy: 0.6991 - val_loss: 1.0577 - val_accuracy: 0.6307\n",
            "Epoch 160/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8153 - accuracy: 0.7019 - val_loss: 1.0425 - val_accuracy: 0.6332\n",
            "Epoch 161/200\n",
            "898/897 [==============================] - 36s 40ms/step - loss: 0.8179 - accuracy: 0.6950 - val_loss: 1.0790 - val_accuracy: 0.6297\n",
            "Epoch 162/200\n",
            "898/897 [==============================] - 36s 40ms/step - loss: 0.8111 - accuracy: 0.6981 - val_loss: 1.0617 - val_accuracy: 0.6241\n",
            "Epoch 163/200\n",
            "898/897 [==============================] - 36s 41ms/step - loss: 0.8092 - accuracy: 0.7024 - val_loss: 1.0565 - val_accuracy: 0.6284\n",
            "Epoch 164/200\n",
            "898/897 [==============================] - 36s 40ms/step - loss: 0.8142 - accuracy: 0.6965 - val_loss: 1.0757 - val_accuracy: 0.6211\n",
            "Epoch 165/200\n",
            "898/897 [==============================] - 36s 40ms/step - loss: 0.8157 - accuracy: 0.6979 - val_loss: 1.0674 - val_accuracy: 0.6204\n",
            "Epoch 166/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8122 - accuracy: 0.6999 - val_loss: 1.1504 - val_accuracy: 0.6043\n",
            "Epoch 167/200\n",
            "898/897 [==============================] - 35s 40ms/step - loss: 0.8114 - accuracy: 0.6996 - val_loss: 1.0651 - val_accuracy: 0.6250\n",
            "Epoch 168/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8144 - accuracy: 0.6978 - val_loss: 1.1357 - val_accuracy: 0.6064\n",
            "Epoch 169/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8108 - accuracy: 0.6984 - val_loss: 1.0781 - val_accuracy: 0.6234\n",
            "Epoch 170/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8124 - accuracy: 0.6979 - val_loss: 1.1069 - val_accuracy: 0.6186\n",
            "Epoch 171/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8066 - accuracy: 0.7007 - val_loss: 1.0849 - val_accuracy: 0.6201\n",
            "Epoch 172/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8090 - accuracy: 0.6978 - val_loss: 1.0631 - val_accuracy: 0.6219\n",
            "Epoch 173/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8052 - accuracy: 0.7019 - val_loss: 1.0694 - val_accuracy: 0.6219\n",
            "Epoch 174/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8072 - accuracy: 0.7042 - val_loss: 1.0471 - val_accuracy: 0.6276\n",
            "Epoch 175/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8121 - accuracy: 0.6994 - val_loss: 1.1027 - val_accuracy: 0.6101\n",
            "Epoch 176/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8086 - accuracy: 0.7025 - val_loss: 1.1574 - val_accuracy: 0.5985\n",
            "Epoch 177/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8080 - accuracy: 0.7002 - val_loss: 1.0508 - val_accuracy: 0.6278\n",
            "Epoch 178/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8109 - accuracy: 0.6978 - val_loss: 1.0871 - val_accuracy: 0.6213\n",
            "Epoch 179/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8042 - accuracy: 0.7019 - val_loss: 1.0542 - val_accuracy: 0.6237\n",
            "Epoch 180/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8067 - accuracy: 0.7016 - val_loss: 1.0972 - val_accuracy: 0.6174\n",
            "Epoch 181/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8043 - accuracy: 0.7036 - val_loss: 1.1019 - val_accuracy: 0.6236\n",
            "Epoch 182/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8056 - accuracy: 0.7029 - val_loss: 1.0981 - val_accuracy: 0.6213\n",
            "Epoch 183/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.7988 - accuracy: 0.7053 - val_loss: 1.0760 - val_accuracy: 0.6197\n",
            "Epoch 184/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8068 - accuracy: 0.7017 - val_loss: 1.0592 - val_accuracy: 0.6259\n",
            "Epoch 185/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8010 - accuracy: 0.7030 - val_loss: 1.0435 - val_accuracy: 0.6329\n",
            "Epoch 186/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.7988 - accuracy: 0.7054 - val_loss: 1.0746 - val_accuracy: 0.6244\n",
            "Epoch 187/200\n",
            "898/897 [==============================] - 36s 40ms/step - loss: 0.8046 - accuracy: 0.7015 - val_loss: 1.0907 - val_accuracy: 0.6138\n",
            "Epoch 188/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.7998 - accuracy: 0.7054 - val_loss: 1.0880 - val_accuracy: 0.6037\n",
            "Epoch 189/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8022 - accuracy: 0.7037 - val_loss: 1.0642 - val_accuracy: 0.6252\n",
            "Epoch 190/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.7934 - accuracy: 0.7087 - val_loss: 1.0981 - val_accuracy: 0.6218\n",
            "Epoch 191/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8079 - accuracy: 0.7021 - val_loss: 1.1068 - val_accuracy: 0.6156\n",
            "Epoch 192/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8084 - accuracy: 0.6996 - val_loss: 1.1021 - val_accuracy: 0.6183\n",
            "Epoch 193/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.7981 - accuracy: 0.7054 - val_loss: 1.0554 - val_accuracy: 0.6339\n",
            "Epoch 194/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.7955 - accuracy: 0.7062 - val_loss: 1.0776 - val_accuracy: 0.6248\n",
            "Epoch 195/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.8003 - accuracy: 0.7046 - val_loss: 1.0709 - val_accuracy: 0.6261\n",
            "Epoch 196/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.7962 - accuracy: 0.7067 - val_loss: 1.0975 - val_accuracy: 0.6216\n",
            "Epoch 197/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.7940 - accuracy: 0.7052 - val_loss: 1.0888 - val_accuracy: 0.6176\n",
            "Epoch 198/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.7973 - accuracy: 0.7062 - val_loss: 1.0808 - val_accuracy: 0.6229\n",
            "Epoch 199/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.7928 - accuracy: 0.7074 - val_loss: 1.0676 - val_accuracy: 0.6257\n",
            "Epoch 200/200\n",
            "898/897 [==============================] - 35s 39ms/step - loss: 0.7969 - accuracy: 0.7067 - val_loss: 1.0434 - val_accuracy: 0.6303\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cePF9z8U-5Fh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "20ab001a-afa5-48db-d377-9be9ab9f2458"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train'], loc='upper left')\n",
        "plt.show()\n",
        "#summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "# plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['lose'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NP4ZaxB-5La",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZU_pW3Ih-5R7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f5183a7c-218f-4de8-d73a-5bbc4b5f6efd"
      },
      "source": [
        "print(\"ahemd_ali\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ahemd_ali\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siPUd1g2-5WN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "521a6ef5-32a5-4202-e10b-04c9a3a950f1"
      },
      "source": [
        "print(\"youssef\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "youssef\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtRdjETH-5ca",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4afffecd-7549-4609-85d5-e496adf066c2"
      },
      "source": [
        "print(\"ahmed_ali\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ahmed_ali\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpJKgDZb-5nH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f32b2ea2-d953-4d5d-e1ed-4320982ebfb6"
      },
      "source": [
        "print(\"ahmed_ali_ahmed\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ahmed_ali_ahmed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYM_Fiim-5uF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ropTwOWg-5rU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dojpmz8F-5kC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjCDzMfJ-5gj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLzsvRjX-5Zw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTWCH9eA-5Pi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWarqOIc-4_E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fY4av1tI-478",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8pBVEdM-41g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AI-21hSA-4v4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgPYfs87-4mx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbC9tzW_-4gr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_wjVxKz-4Wv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9hYGj5j-4US",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I57lBk3y-4LP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKWiZj_B-4Ik",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GVSIPyp-3_y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xf300HS-39l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}